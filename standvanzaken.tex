\chapter{\IfLanguageName{dutch}{Stand van zaken}{State of the art}}
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

\section{Inhoud}

In het hoofdstuk \ref{ch:inleiding}: \nameref{ch:inleiding} werd al gesproken over interviews, methodes voor geluidsgeneratie en libraries voor geluidsverwerking. In dit hoofdstuk zullen alledrie die onderwerpen verder uiteengezet worden. Deze onderwerpen vormen de primaire en een deel van de secundaire bronnen van dit onderzoek.

\section{Interviews}

Voor het opstellen van de empirische tests werd er gezocht naar real-life cases. Zo konden de tests representatief zijn voor usecases uit de muzieksector.

De cases zijn verkregen uit interviews met bands, artiesten en opnamestudio's. Deze sectie gaat over het verkrijgen van de interviews en de hoofdpunten ervan.

TO DO:
\begin{itemize}
    \item Push interviews naar git.
    \item Transcribe.
    \item hoofdpunten noteren per interview.
\end{itemize}{}

\subsection{Correspondentie}

Tabel \ref{table:correspondenten} toont alle artiesten die gevraagd zijn om geïnterviewd te worden. De selectie van mogelijke kandidaten hield rekening met volgende criteria:

\begin{itemize}
    \item Er werden zoveel mogelijk instanties gevraagd zodat er van iedere branche\footnote{Muzikant, artiest, band, opnamestudio, sound designer, producer, radio etc.} in de muzieksector zeker een interview verkregen is.
    \item Iedere branche kon live geïnterviewd worden zodat er mogelijkheid was tot doorvragen.
    \item De interviewee heeft ervaring met live optreden en kan spreken over zijn geluidsinstallatie en de good-practice ervan.
\end{itemize}{}

Alle correspondentie - de betrachtingen tot het verkrijgen van interviews - staan in tabel \ref{table:correspondentie}. Iedere instantie heeft meerdere maals een verzoek gekregen. 

Van de 25 gevraagde instanties heeft minder dan de helft geantwoord. Slechts bij vier van die helft is het gelukt om een interview af te nemen. Sommige instanties annuleerden hun afspraak. Andere instanties stuurden de aanvraag - soms cyclisch - door naar medewerkers.

De vier geslaagde interviews zijn opgenomen. U kan deze terugvinden in de bronverwijzing. Het doel van deze interviews was het verkrijgen van real-life usecases. Door de respons is de usecase van een branch verkregen van een enkele instantie. De omvang van de interviews is te klein om een representatieve steekproef te zijn. De usecases verkregen van deze instanties zijn wel gebruikt in de empirische tests. Dit door gebrek aan alternatieve data.

\subsection{Bart Vincent (Producer)}

Het opgenomen interview met Bart Vincent kan teruggevonden worden op GitHub \autocite{bartvincent}. Er staat een transcriptie van dit interview in appendix \ref{trans:bartvincent}. Dit interview werd afgenomen op 11 april 2019.

\subsubsection*{Persona}

Vincent is de producer voor artiesten zoals Sundahl, Kapitan Korsakov en de befaamde jazz zangeres Melanie De Biasio. Hij doet zowel de opname als het live geluid voor zijn artiesten en heeft ervaring met het schrijven en opvoeren van muziek.

\subsubsection*{Interview}

Vincent meldt in zijn interview dat er reeds een evolutie gaande is in de muzieksector. Digitale mengtafels komen tegenwoordig veel meer voor dan twee à drie jaar geleden. Een must voor deze apparatuur is dat er een fysieke user-interface is \autocite{bartvincent}.

In zijn werkproces is hij een idealist. In opname zoekt hij samen met zijn artiesten naar het gewenste geluid. Hij probeert dit vervolgens vast te leggen met oog op zo min mogelijk aanpassing in post-productie. Hij benadrukt dat een goede band en communicatie met de artiesten hier essentieel is \autocite{bartvincent}.

``Er is zeer weinig dat nog real-time aangepast wordt,'' meldt Vincent over zijn ervaring als geluidstechnicus \autocite{bartvincent}. ``Als een muzikant te luid speelt bij de sound check, dan communiceer ik dat ook. Maar live, tijdens het concert, pas ik daar weinig van aan.''

Vincent verwelkomt de digitalisering. Hij is van idee dat een computer nooit het werk van een mens kan volbrengen. In de tools die de mens bijstaan in productie ziet hij wel een verbeterende toekomst. ``Het verwantschap met het instrument gaat anders zijn, maar het is nog steeds een instrument dat je kan leren spelen,'' aldus Vincent \autocite{bartvincent}.

\subsubsection*{Opstelling}

Vincent spreekt zowel over zijn live opstelling alsook over zijn opstelling in opname van Melanie De Biasio. Zo'n 50-tal tracks krijgen elk equalization en compressie toegepast. Op de instrumentale tracks past hij vijf effecten toe. Dit wordt op twintig tracks geschat \autocite{bartvincent}.

\subsection{Peter Boone (Producer en Muzikaal Artiest)}
\label{sub:boone}

Het opgenomen interview met Peter Boone kan teruggevonden worden op GitHub \autocite{peterboone}. Er staat een transcriptie van dit interview in appendix \ref{trans:peterboone}. Dit interview werd afgenomen op 25 april 2019.

\subsubsection*{Persona}

Peter Boone staat gekend als een \textit{jack of all trades} in de muziek wereld. Naast zijn job als producer gaat hij ook door als muzikant en arrangeur. Hij is het meest gekend als keyboardist voor EBM band A Split-Second waar hij in de jaren '80 tot '90 mee tourde.

\subsubsection*{Interview}

``Op het moment dat de digitalisatie begon, kon het gewoon niet digitaler,'' zegt Boone, ``met momenten vond ik het ambetant dat zelfs een microfoon nog analoog was.'' \autocite{peterboone} De prestatie van digitale mengtafels vond hij altijd maar teleurstellend. Dit ligt volgens hem aan de resolutie van het geluid. De meeste mengtafels werken in 16 bit aan 44.1 kHz wat hij CD-kwaliteit en beschamend slecht noemt \autocite{peterboone}.

Er zijn mengtafels die 88.2 kHz en zelfs 192 kHz aankunnen. Deze tools zijn mede door het grote prijs etiket niet veel verspreid. Boone legt uit dat dit door een standardisatie in geluid. In de context van live muziek looft hij digitale mengtafels omdat alles veel sneller moet gebeuren. Het publiek gaat daarbij ook niet struikelen over de 44.1 kHz. ``Het werkt zeer professioneel,'' aldus Boone \autocite{peterboone}.

Wanneer het echter aankomt op het vastleggen van het geluid, moet alles zo lang mogelijk analoog blijven. Boone meldt: ``eender wat je \verb+[aan 44.1 kHz]+ van subtiliteit in \verb+[geluid]+ wilt steken gaat verloren omdat de notatie niet goed genoeg is. Eens je daar naar 88.2 kHz gaat wordt een galm terug een ruimte inplaats van een effectje.'' \autocite{peterboone}

Desondanks dat Boone deel uitmaakte van een Electronic Body Music (EBM) band, is hij wel volledig afgestapt van hardware synthesizers. Tegenwoordig gebruikt hij enkel nog software synthesizers. Net zoals de plug-ins in programma's voor audiobewerking zijn de algoritmes van software synthesizers exacte kopieën van wat de analoge machines achter de schermen doen. In tegenstelling tot de plug-ins hoor je, volgens hem, geen hoorbaar verschil tussen hardware synthesizers en de hedendaagse software varianten ervan \autocite{peterboone}.

Boone zijn beeld van de digitalisatie is gemengd. Hij is zelf een grote voorstander van analoog, de keuze om een overstap naar digitaal te maken is volgens hem zeer afhankelijk van het genre van de muziek.  ``\ldots de tijd gaat vooruit \textit{whether you like it or not}. Ik ben er \ldots van overtuigd dat je \textit{the best of both worlds} moet gebruiken.'' \autocite{peterboone}

\subsubsection*{Opstelling}

EBM bands zijn zeer rechtuit. Waar bij de opnames van bands vaak instrumenten meerdere maals opgenomen worden om een \textit{wall of sound} te creëren, zijn EBM bands zeer rechtuit. Voor dat genre worden er zowel op band als digitaal zo'n 24 sporen gebruikt.

\subsection{Thomas Houthave (Sound Designer)}

Het opgenomen interview met Thomas Houthave kan teruggevonden worden op GitHub \autocite{thomashouthave}. Er staat een transcriptie van dit interview in appendix \ref{trans:thomashouthave}. Dit interview werd afgenomen op 11 april 2019.

\subsubsection*{Persona}

Na zijn studies aan SAE Institute Amsterdam vond Houthave al snel werk bij productiehuizen zoals Videohouse en Studio Brussel. In 2015 stichtte hij Klankwerk op waar hij nu zelf als sound designer en engineer werkt. Hij werkt met klanten zoals Ted-X, Philips en Abu Dhabi. \autocite{klankwerkbio}

\subsubsection*{Interview}

Volgens Houthave was er in de jaren '90 reeds een eerste digitale evolutie in de muzieksector. Veel consumenten namen snel de stap naar digitaal eens het na enige tijd ook goedkoper werd. Houthave spreekt veel over opstellingen en dat die vandaag vaak hybride zijn. Hiermee bedoelt hij dat er bij opnames een analoog mengpaneel gebruikt wordt, maar dat de opslag en bewerking zeker digitaal zijn. \autocite{thomashouthave}

Omdat Houthave commercieel en op korte deadline met zijn klanten werkt, heeft hij veel baat bij digitaal. ``Sommige mensen zweren bij analoog maar tegenwoordig staat het zo dicht dat alles subjectief is,'' aldus Houthave. \autocite{thomashouthave} 

Hoewel zijn professionele werkomgeving - naast de opnameapparatuur - reeds volledig digitaal is, ziet Houthave meer potentieel in software dan wat er momenteel op de markt is. Voornamelijk met het gebruik van AI. Hij spreekt in zijn interview over de \textit{Master Assistant} van Izotope Osone 8, een programma voor geluidbewerking. Het is een feature die equalization instellingen kiest voor de gebruiker op basis van een vooraf gegeven referentie track. De assistant zal proberen om het geluid van opnames zo goed mogelijk te laten klinken als de referentie track. Houthave hoopt dat de toepassing van AI op zulke, alsook op andere features meer onderzocht kan worden. \autocite{thomashouthave}

\subsubsection*{Opstelling}

Houthave werkt met zelfgemaakte of gekochte samples. De samples moeten weinig bewerkt worden; ze zijn al kant en klaar. Naast de standaard equalization en compressie worden er dus weinig tot geen effecten gebruikt.\newline Voor zijn projecten gebruikt Houthave ongeveer 100 tot 150 tracks. \autocite{thomashouthave}

\subsection{Vagabundos (Band)}

Het opgenomen interview met Vagabundos kan teruggevonden worden op GitHub \autocite{vagabundos}. Er staat een transcriptie van dit interview in appendix \ref{trans:vagabundos}. Dit interview werd afgenomen op 17 april 2019.

\subsubsection*{Persona}

Vagabundos is een Gentse funk band met enkele Britse en Braziliaanse roots. Ze zijn opgericht in 2014. Na de release van een album, twee EP's en meerdere internationale tours maken ze zich nu klaar om een nieuw album aan te kondigen. Het is een charismatische groep met een grote passie voor zowel hun werk als het creatieproces dat erachter zit. \autocite{vagabio}

\subsubsection*{Interview}

Refereer naar tabel \ref{tab:vagapeeps} voor de deelnemers van dit interview.

Na vijf jaar op de planken en snel gegroeide faam heeft Vagabundos kennis gemaakt met reeds veel stijlen van productie. Ze zijn het meest bekend met de opnamestudio van Peter Boone. Zijn werkproces staat beschreven in sectie \ref{sub:boone}. Naast Boone bespreekt Vagabundos in hun interview ook nog het productieprocessen van BOMA studio in Gent en van hun eigen gitarist Saulo Soneghet. \autocite{vagabundos}

BOMA studio kon niet geïnterviewd worden voor dit onderzoek. Zo staat in tabel \ref{table:correspondentie}.

Vagabundos bespreekt het productieproces van Soneghet. Soneghet wordt beschreven als een perfectionist in zijn werk. Hij hangt veel belang aan postproductie. De band vertelt over hoe Soneghet een nummer zodanig veel op kan blinken tot er bijna geen human touch meer in de herkennen is. In opname neemt hij alles apart op zodat de het brongeluid zo klaar mogelijk is. \autocite{vagabundos}

Volgens Vagabundos is er geen goed of slecht in opname. Iedere producer of band heeft een eigen manier. De manier is meest afhankelijk van het gewenste geluid. ``Peter is Peter and he likes another kind of sound so he records it in another kind of way,'' meldt Adam Wilson, frontman van de band. \autocite{vagabundos} Boone meldde in zijn interview al dat bepaalde genres meer baat zouden hebben bij de digitalisatie dan andere.  \autocite{peterboone}

\subsubsection*{Opstelling}

Het aantal tracks dat Vagabundos gebruikt voor hun live opstellingen loopt al snel op tot 20. Dat worden er 40 in opname. Adam (Woodie Bundo) Vandenhaute meldt dat hij op zijn basgitaar uitzonderlijk maximum drie actieve effecten heeft. Meestal zijn dit er maar 1 of 2.

Soneghet heeft ook ervaring met productie voor metal bands. Daar gebruikt hij 50 tracks met 5 effecten op de instrumentale tracks daarvan. 

Alle sporen krijgen equalization en compression.

\section{Methodes voor Geluidsgeneratie en -verwerking}

\textcite{methodes} beschrijft in zijn artikel vijf fundamentele methodes voor geluidsgeneratie. Voor dit onderzoek werd gezocht naar een methode die voldoet aan volgende selectiecriteria.

\begin{itemize}
    \item Welke methode de muzieksector het intuïtiefst kon gebruiken.
    \item Welke methode programmatorisch het efficientst werkt.
    \item Welke methode het meest design capaciteiten biedt aan artiesten en sound designers.
\end{itemize}{}

De vijf fundamentele methodes beschreven door \textcite{methodes} zijn de volgende.

\begin{itemize}
    \item Subtractive Synthesis
    \item Additive Synthesis
    \item Granular Synthesis
    \item Wavelet en Corpus-based Synthesis
\end{itemize}{}

De werking van deze methodes en de selectiecriteria worden hieronder verder toegelicht.

\subsection{Subtractive Synthesis}

Bij subtractive synthesis start de gebruiker met een harmonisch rijke geluidsgolf. Een golf is harmonisch rijk wanneer het veel subfrequenties bevat. Voorbeelden hiervan zijn zaagtand-, blok- en driehoeksgolven Wanneer de golf puur gehoord wordt zal de fundamentele frequentie het dominantst klinken \autocite{harmonics}. Het is de taak van de gebruiker om door middel van frequentiefilters de ongewenste delen van het frequentiespectrum weg te halen en zo het geluid te modelleren \autocite{subtractive}

\textcite{subtractive} bespreken in hun artikel methodes voor digitale geluidsgeneratie en -verwerking. Deze methodes zijn slechts een benadering van wat analoge synthesizers doen. Maar in tegenstelling tot andere pogingen om analoge geluidsgeneratie te digitaliseren zijn de resultaten van deze methodes niet te onderscheiden van het analoge geluid \autocite{subtractive}.

Subtractive synthesis is tot vandaag nog steeds de standaard voor geluidsdesign sinds Robert A. Moog de eerste subtractive synthesizer modules uitbracht in de jaren '60 \autocite{subtractive}. \textcite{guitarpedals} beschrijft in zijn artikel hoe sommige effecten, die vandaag terug te vinden zijn in de effectpedalen voor gitaristen, digitaal verwerkt kunnen worden; allemaal door middel van subtractive synthesis.

\subsection{Additive Synthesis}

Additive synthesis is de tegenhanger van subtractive synthesis. Sinusgolven staan er gekend om maar één frequentie te hebben; hun fundamentele frequentie. Bij additive synthesis gaat de gebruiker tal van sinusgolven bij elkaar optellen om complexere geluiden te bekomen \autocite{additive}.

Voor kleine toepassingen is deze berekening nog haalbaar voor een digitale workstation. Maar van het moment dat de geluiden complexer en harmonisch rijker moeten zijn, loopt de doorlooptijd van de generatie linear op met het aantal sommen van de additieve golf \autocite{additive}.

Wanneer men harmonisch rijke golven wilt genereren zoals de zaagtandgolf, is dit onmogelijk te volbrengen op additieve wijze door het oneindig aantal sommaties dat berekend moet worden \autocite{harmonics}.

\subsection{Granular Synthesis}

Bij granular synthesis start de gebruiker met een of meerdere zeer korte geluidsfragmenten - grains - die aanzien worden als een periode van een geluidsgolf. De gebruiker zal die periode verschillende keren kopiëren en verschalen. De periode krijgt vervolgens ook een aanvangsttijd toegewezen. Door verschillende grains op die manier met elkaar te vermengen, kan de gebruiker het gewenste geluid modelleren \autocite{granular}.

Granular synthesis is van eigen al een techniek die enkel digitaal toegepast kan worden. Met de IT-sector als doelpubliek is het een zeer aantrekkelijke methode voor sound synthesis. De techniek is zeer bruikbaar voor geluidssimulaties en -imitaties, vooral door middel van een AI \autocite{granular}.

\textcite{granular} legt in zijn paper zelfs een manier uit om in real-time (live) aan granulair geluid te genereren. Zelf geeft hij aan het einde van zijn artikel wel toe dat hij geen toekomst ziet voor granular synthesis in de muziekproductie. Dit omdat er teveel parameters zijn die de gebruiker moet beïnvloeden.

\subsection{Wavelet en Corpus-based Synthesis}

Deze twee generatie methodes zijn soorten van granular synthesis. Door hun verschil in implementatie zijn ze elk toepasbaar op andere vlakken.

\subsubsection{Wavelet Synthesis}

Wavelet synthesis biedt de gebruiker niet meerdere maar slechts één periode om het modelleerproces mee te starten. De periode, hier wavelet genoemd, is op voorhand specifiek gekozen door de gebruiker om het gewenste geluid te kunnen bekomen. Verder verloopt het modelleerproces volledig zoals granular synthesis \autocite{wavelet}.

Deze methode wordt meer gebruikt wanneer men zeer gedetailleerd geluid wilt nabootsen. Het modeleerproces vereist dat de gebruiker een goed inzicht heeft in muziektheorie en vergt ook dat het geluid iteratief gemodeleerd wordt 
\autocite{wavelet}. Real-time is het dus slecht toepasbaar.

\subsubsection{Corpus-based Granular Synthesis}

Deze granulaire generatiemethode haalt de grains op uit een databank - de corpus - van vooraf opgenomen geluiden. Deze methode wordt vooral gebruikt wanneer men een specifiek geluid wilt imiteren. Een zoekalgoritme of AI weet dan exact waar hij gelijkaardige grains terug kan vinden en probeert dan het originele geluid na te bootsen aan de hand van die grains 
\autocite{methodes}.

Corpus-based is niet toepasbaar wanneer de gebruiker nieuwe geluiden wilt maken. Niet alleen heeft het dezelfde tekortkomingen als gewone granulaire geluidsgeneratie, het heeft ook nog extra vrijheidsgraden van welke grains te kiezen uit de hele corpus.

\section{Libraries}

\subsection{JASS}

\textcite{jass} ontwikkelden JASS (Java Audio Synthesis System) voor hun onderzoek naar efficiente geluidsgeneratie. Deze library synthetiseert zeven voorafgaande onderzoeken naar modellen voor geluidsgeneratie die bedoeld zijn voor geluidseffecten in video games en simulaties. 

\textcite{jass} leggen uit hoe verschillende libraries verschillende doeleinden, implementaties en kosten hebben. Hun doel met JASS is om een library te schrijven die, naast alle requirements die opgelijst staan in hun paper, ook een breed scala van mogelijke toepassingen heeft. JASS is dus bedoeld als all-round library voor om het even welke sector \autocite{jass}.

\subsubsection*{De Code}
\label{sec:jass_code}

JASS kan teruggevonden worden op de website van van den Doel \autocite{jasscode}.

In hun paper leggen \textcite{jass} de innerlijke werking van JASS uit. Hier valt op dat het een modulaire\footnote{Iedere module heeft zijn eigen atomaire rol (oscillator, filter, compressor, versterker etc.). Door ze met elkaar te verbinden - of patchen - krijgt de gebruiker een zelf ontworpen stramien van parameters waarmee hij zijn geluid kan boetseren.} library is. De ontwikkelaar kan zijn eigen modules ontwikkelen door over te erven van gegeven abstracte klassen en interfaces  \autocite{jass}. 

Dit is ook hoe programma's voor geluidsbewerking en (modulaire) synthesizers opgebouwd zijn. Modulaire programma's zijn intuïtief voor gebruikers uit de muzieksector \autocite{bartvincent}.

Een ontwikkelaar instantieert een geluidsgenererende subklasse. Deze klasse erft dus van de \verb+Out+ klasse. Bijgevolg moet deze klasse de \verb+computeBuffer+ methode implementeren. Deze methode kan twee dingen doen. Ofwel genereert het een buffer. Ofwel verwerkt het een buffer die de klasse verkrijgt via een \verb+Source+ attribuut. Alle klassen die erven van \verb+In+ en \verb+InOut+ hebben een \verb+addSource+ methode waarmee een \verb+Source+ toegevoegd kan worden \autocite{jass}.

Wanneer een stramien van verwerkte buffers uiteindelijk via een \verb+SourcePlayer+ aangesloten wordt op de audio output van de machine, kan de buffer gehoord worden. Evenals subklassen van \verb+In+ en \verb+InOut+ kan een \verb+SourcePlayer+ meerdere \verb+Source+'s hebben \autocite{jass}.

\subsection{Beads}

Beads is een open-source Java library gemaakt door Oliver Bown. Het project is in 2008 tot stand gekomen met behulp van Monash University in Melbourne en heeft in 2014 zijn laatste update gekregen \autocite{beads}.

De library is bedoeld voor het schrijven van real-time\footnote{Wanneer een library of programma multi-threaded werkt zodat de gebruiker met het geluid kan interageren terwijl het gegenereerd of bewerkt wordt.} programma's voor geluidsverwerking. Java was hier onmiddellijk de taal van voorkeur omdat het open-source is. De ontwikkelaars melden op hun site dat ze een zeer flexibele IO-laag geïmplementeerd hebben. De library functioneert zo in verschillende contexten \autocite{beads}. 

Het doel van Beads is het vergemakkelijken audio-implementatie. Bown en zijn team hopen om de ontwikkeling van audio applicaties toegankelijker te maken voor de standaard programmeur \autocite{beads2}.

\subsubsection*{De Code}

Programmeren in Beads start met het instantiëren van een \verb+AudioContext+. Deze klasse vraagt in zijn constructor naar een audio output device. Het selecteren van een audio output device is mogelijk in native Java \autocite{beadsdocs}.

Beads biedt een paar reeds voorgeprogrammeerde oscillatoren aan. Deze zijn ondergebracht in de \verb+Buffer+ klasse. De golven kunnen afgespeeld worden met de \verb+WavePlayer+ klasse \autocite{beadsdocs}.

Beads werkt, net zoals JASS, ook modulair. Klassen die erven van \verb+UGen+ implementeren de \verb+addInput+ methode. De methode vraagt een andere \verb+UGen+ als parameter wiens output de input wordt van de betreffende \verb+UGen+ \autocite{beadsdocs}.

Om \verb+UGen+'s te horen, moeten ze aangesloten worden op de \verb+AudioContext+. De \verb+AudioContext+ kan meerdere \verb+UGen+'s als input aanvaarden. Vervolgens moet de ontwikkelaar de \verb+start+ methode oproepen in \verb+AudioContext+ om het geluid af te laten spelen \autocite{beadsdocs}.

\subsection{JSyn}

JSyn is - de naam verraadt het - een Java library die traditionele modellen van modulaire synthesizers imiteert \autocite{jsyn}. Net zoals Beads is het real-time en open-source verkrijgbaar op GitHub \autocite{jsyngit}.

Mobileer Inc. hebben naast JSyn ook twee andere software audio projecten gereleased: JMSL (Java Music Specification Language) en PortAudio. JMSL is een Java-based specificatie taal waarin gebruikers instrumenten en composities kunnen definiëren. PortAudio is een cross-platform audio IO-library voor C \autocite{jsyn}.

\subsubsection*{De Code}

Beschouw de documentatie van JSyn \autocite{jsyndocs}. Daar vinden we een aantal herkenbare klassen terug zoals basis oscillatoren (sinus-, zaagtand-, driehoeks- en blokgolf), verschillende soorten filters (low-pass, high-pass, band-pass, multi-pole etc.) en zelfs effecten (delay, envelope etc.).

JSyn baseert zich op één moederklasse: \verb+Synthesizer+. Wanneer een ontwikkelaar modules instantieert, moeten die via de \verb+add+ methode toegevoegd worden aan de \verb+Synthesizer+ vooraleer ze gehoord kunnen worden. De \verb+Synthesizer+ klasse staat in voor het starten van alle toegevoegde modules en beslist ook de geluidskwaliteit van de output \autocite{jsyndocs}.

De genererende en verwerkende klassen hebben - net zoals in JASS - een methode die een buffer genereert of verwerkt. Kijk hiervoor terug naar \ref{sec:jass_code}. De methode heet \verb+pullData+ en verkrijgt de te verwerken buffers via de \verb+UnitInputPort+-attributen van de klassen \autocite{jsyndocs}.

JSyn is, evenals Beads en JASS ook modulair. Het verbinden van klassen is mogelijk door de \verb+UnitInputPort+- en \verb+UnitOutputPort+-attributen van genererende en verwerkende klassen. Via de \verb+connect+ methode kan een ontwikkelaar een \verb+UnitOutputPort+ connecteren aan een \verb+UnitInputPort+ \autocite{jsyndocs}.

Een stramien van verwerkte buffers, wordt via de \verb+LineOut+ klasse op de audio output van de machine aangesloten. Wanneer de ontwikkelaar de \verb+start+ methode oproept op zowel de \verb+LineOut+ als de \verb+Synthesizer+, weerklinkt het geluid. Het \verb+UnitInputPort+-attribuut van \verb+LineOut+ kan meerdere inputs ontvangen \autocite{jsyndocs}.

\subsection*{Vergelijking van de Libraries}

\begin{longtable}[c]{l|lll}
         & \textbf{Beads} & \textbf{JASS} & \textbf{JSyn} \\ \hline
        \textbf{Real-time} & Ja & Ja & Ja \\
        \textbf{Modulair} & Ja & Ja & Ja \\
        \textbf{Buffer methode} & calculateBuffer & computeBuffer & pullData \\
        \textbf{Synthesis methode} & Subtractive & Subtractive & Subtractive \\
    \caption{Vergelijking van de drie testlibraries.}
    \label{tab:vergelijking}
\end{longtable}

Wanneer we de documentatie van de drie libraries beter bekijken, valt op dat hun code in essentie hetzelfde doet. Niet alleen hebben ze alle gelijkenissen uit tabel \ref{tab:vergelijking}, de architectuur van het verbinden van genererende en verwerkende buffers is duidelijk ook typerend aan sound libraries.

Uitzonderlijk bij JSyn is wel dat alle parameters een \verb+UnitInputPort+ zijn. Neem een low-pass filter (LPF) als voorbeeld. Gegeven een harmonisch rijke geluidsgolf gaat een LPF alle aanwezige frequenties hoger dan een gegeven cut-off frequentie weg filteren. Het te filteren geluid is hier de input - bij zowel JSyn als andere libraries is dit het geval. De cut-off frequentie is hier een parameter voor de module.\newline
Bij de meeste libraries zijn zulke parameters statische getallen. JSyn behandelt zulke parameters als \verb+UnitInputPort+'s \autocite{jsyndocs}.

De filosofie van object-oriented programming is het modelleren van de echte wereld. In dit voorval is JSyn de beste representatie van echte modulaire synthesizers. Parameters van modules zijn maar zelden statische waarden. Artiesten willen een interactieve band hebben met hun geluid. Daarvoor moeten zulke parameters dynamisch aangepasbaar zijn \autocite{vagabundos}. In het geval van modulaire synthesizers \textit{"moduleert"} men parameters door middel van \textit{"control voltage"} \autocite{modular}.

\iffalse

Dit hoofdstuk bevat je literatuurstudie. De inhoud gaat verder op de inleiding, maar zal het onderwerp van de bachelorproef *diepgaand* uitspitten. De bedoeling is dat de lezer na lezing van dit hoofdstuk helemaal op de hoogte is van de huidige stand van zaken (state-of-the-art) in het onderzoeksdomein. Iemand die niet vertrouwd is met het onderwerp, weet nu voldoende om de rest van het verhaal te kunnen volgen, zonder dat die er nog andere informatie moet over opzoeken \autocite{Pollefliet2011}.

Je verwijst bij elke bewering die je doet, vakterm die je introduceert, enz. naar je bronnen. In \LaTeX{} kan dat met het commando \texttt{$\backslash${textcite\{\}}} of \texttt{$\backslash${autocite\{\}}}. Als argument van het commando geef je de ``sleutel'' van een ``record'' in een bibliografische databank in het Bib\LaTeX{}-formaat (een tekstbestand). Als je expliciet naar de auteur verwijst in de zin, gebruik je \texttt{$\backslash${}textcite\{\}}.
Soms wil je de auteur niet expliciet vernoemen, dan gebruik je \texttt{$\backslash${}autocite\{\}}. In de volgende paragraaf een voorbeeld van elk.

\textcite{Knuth1998} schreef een van de standaardwerken over sorteer- en zoekalgoritmen. Experten zijn het erover eens dat cloud computing een interessante opportuniteit vormen, zowel voor gebruikers als voor dienstverleners op vlak van informatietechnologie~\autocite{Creeger2009}.

\lipsum[7-20]

\fi
